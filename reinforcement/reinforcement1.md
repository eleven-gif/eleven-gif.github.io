# 强化学习模型基础

## 八要素

强化学习本质为一个决策序列模型，根据当前状态，做出一定的决策，作出决策之后会改变状态，同时会得到我们做决策的延迟奖励，即在下一个状态才能拿到上一个状态的奖励。

1. 环境状态`S`，即我们所处的状态空间,t时刻状态为S<sub>t</sub>
2. 个体动作A，我们在t时刻所做的动作为A<sub>t</sub>
3. 环境奖励R，我们在t时刻个体处在S<sub>t</sub>状态，所采取动作A<sub>t</sub>，对应奖励R<sub>t+1</sub>会在t+1时刻获得
4. 个体策略，在S<sub>t</sub>状态下，选取A<sub>t</sub>的概率记为P，P越大选择的概率越高
5. 采取行动后的价值v，其实是一个倒推的过程，在s状态下采取了行动之后的到奖励R<sub>t+1</sub>，然后会一直延续到状态结束，得到一个累计价值，类似于下象棋，一步棋会影响后去知道结束，如果赢了，这一步棋的v就很高。
6. 衰减因子，每个后续状态的奖励是有衰减的，r为0到1的数，即R<sub>t+1</sub>完全计入v的奖励，然后R<sub>t+2</sub>就会乘上r，后面同理，个人理解为对后续状态的影响是减弱的，因为别的状态也会转移过去。
7. 状态转化模型，即概率状态机，在状态s下采取行动a转移到下一个状态的概率。
8. 探索率，通常我们会选择当前轮迭代价值最大的动作，但是可能会陷入局部最优，所以有一定的概率不选择当前轮价值最大的动作。